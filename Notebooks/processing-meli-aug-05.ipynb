{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import udf,pandas_udf\n",
    "import pyspark.sql.types as T\n",
    "from  pyspark.ml.feature import QuantileDiscretizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import interp1d\n",
    "from itertools import product\n",
    "import math\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T21:49:06.929848Z",
     "iopub.status.busy": "2021-08-20T21:49:06.929387Z",
     "iopub.status.idle": "2021-08-20T21:49:44.540115Z",
     "shell.execute_reply": "2021-08-20T21:49:44.538884Z",
     "shell.execute_reply.started": "2021-08-20T21:49:06.929764Z"
    },
    "id": "Af17-bWHl2pf",
    "outputId": "061cd25a-988b-4e63-c199-4cab86d56025"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_window(partitionby, orderby = None, rangebetween = None):\n",
    "    out = f\"Window.partitionBy('{partitionby}')\"\n",
    "    if orderby is not None:\n",
    "        out = out + f\".orderBy('{orderby}')\"\n",
    "    if rangebetween is not None:\n",
    "        out = out + f\".rangeBetween({rangebetween[0]}, {rangebetween[1]})\"\n",
    "    return eval(out)\n",
    "    \n",
    "    \n",
    "def plot_frames_train_val(train, validation, frames, main, x = \"id\", y1 = \"cumsum\", y2 = \"cumsum\", ax1_lab = \"train\", ax2_lab = \"Validation\", rows = 7, cols = 20):\n",
    "    fig,axs =  plt.subplots(rows, cols, figsize = (20,10))\n",
    "    k = 0\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            try:\n",
    "                train_data  = train[train.sku.isin([frames[k]])]\n",
    "                val_data  = validation[validation.sku.isin([frames[k]])]\n",
    "                l1 = axs[i][j].scatter(train_data[x], train_data[y1], c = \"r\", label = ax1_lab, alpha = 0.5)\n",
    "                l2 = axs[i][j].scatter(val_data[x], val_data[y2], c = \"b\", label = ax2_lab, alpha = 0.5)\n",
    "                axs[i][j].set_xticks([])\n",
    "                axs[i][j].set_yticks([])\n",
    "                axs[i][j].title.set_text(frames[k])\n",
    "            except:\n",
    "                pass\n",
    "            k += 1\n",
    "    fig.legend([l1, l2], labels = [ax1_lab.title(), ax2_lab.title()])\n",
    "    plt.subplots_adjust(right=0.9)\n",
    "    fig.suptitle(main.title())\n",
    "    plt.show()\n",
    "     \n",
    "        \n",
    "@udf(T.IntegerType())\n",
    "def count_zeros(x):\n",
    "    counter = 0\n",
    "    for i in x:\n",
    "        if i == 0.0:\n",
    "            counter += 1\n",
    "        else:\n",
    "            break\n",
    "    return counter\n",
    "    \n",
    "    \n",
    "@udf(T.IntegerType()) \n",
    "def are_consecutive_dates(x):\n",
    "    x = sorted([datetime.strptime(i, \"%Y-%m-%d\") for i in x])\n",
    "    res = True\n",
    "    for idx in range(1, len(x)):\n",
    "        if (x[idx] - x[idx - 1]).days != 1:\n",
    "            res = False\n",
    "            break\n",
    "    return res\n",
    "\n",
    "\n",
    "def forward_fill(window, data, column):\n",
    "     return data.withColumn(column, F.last(column, True).over(window)) \n",
    "    \n",
    "def write_data(data, name):\n",
    "    data.coalesce(1).write.format(\"parquet\").mode(\"overwrite\").save(name)\n",
    "    \n",
    "    \n",
    "def proportion_transform(x, var, drop_first = False):\n",
    "    out = x.groupBy([\"sku\", var]).count()\n",
    "    out = out.groupBy(\"sku\").pivot(var).sum(\"count\").na.fill(0)\n",
    "    distinct_values = [row[0] for row in x.select(var).distinct().collect()]\n",
    "    for i in distinct_values:\n",
    "        denominator = set(distinct_values) - set(i)\n",
    "        denominator = [f\"F.col('{j}')\" for j in denominator]\n",
    "        denominator = \"+\".join(denominator) \n",
    "        expression = f\"out.withColumn('{i}_prop', F.col('{i}')/({denominator}))\" \n",
    "        out = eval(expression)\n",
    "    out = out.drop(*distinct_values)\n",
    "    if drop_first:\n",
    "        out = out.drop(f\"{distinct_values[0]}_prop\")\n",
    "    return out.na.fill(0)\n",
    "\n",
    "\n",
    "def create_proportion_columns(x):\n",
    "    listing_type = proportion_transform(x, \"listing_type\")\n",
    "    shipping_payment = proportion_transform(x, \"shipping_payment\")\n",
    "    shipping_logistic_type = proportion_transform(x, \"shipping_logistic_type\")\n",
    "    minutes_active = x.groupBy(\"sku\").avg(\"minutes_active\").withColumnRenamed(\"avg(minutes_active)\", \"minutes_active_avg\")\n",
    "    selling_rate = x.groupBy(\"sku\").avg(\"selling_rate\").withColumnRenamed(\"avg(selling_rate)\", \"selling_rate_avg\")\n",
    "    price = x.groupBy(\"sku\").avg(\"current_price\").withColumnRenamed(\"avg(current_price)\", \"price_avg\")\n",
    "    features = (listing_type.join(shipping_payment, \"sku\")\n",
    "            .join(shipping_logistic_type, \"sku\")\n",
    "            .join(minutes_active, \"sku\")\n",
    "            .join(selling_rate, \"sku\")\n",
    "            .join(price, \"sku\")) \n",
    "    return features\n",
    "\n",
    "\n",
    "def get_dof(X, X_active):\n",
    "    X = X.withColumn(\"dayofweek\", F.dayofweek(\"date\"))\n",
    "    X_active = X_active.withColumn(\"dayofweek\", F.dayofweek(\"date\"))\n",
    "    dof_X = X.groupBy(\"sku\").pivot(\"dayofweek\").sum(\"sold_quantity\").na.fill(0)\n",
    "    dof_X_active = X.groupBy(\"sku\").pivot(\"dayofweek\").sum(\"sold_quantity\").na.fill(0)\n",
    "    dof_X = dof_X.withColumn('sum',sum([F.col(c) for c in dof_X.columns]))\n",
    "    dof_X_active = dof_X_active.withColumn('sum',sum([F.col(c) for c in dof_X_active.columns]))\n",
    "    dof_X = dof_X.select(F.col(\"sku\"), *[F.col(x)/F.col(\"sum\") for x in dof_X.columns[1:-1]]).drop(\"sum\")\n",
    "    dof_X_active = dof_X_active.select(F.col(\"sku\"), *[F.col(x)/F.col(\"sum\") for x in dof_X_active.columns[1:-1]]).drop(\"sum\")\n",
    "    for i,j in zip(range(7), dof_X.columns[1:]):\n",
    "        dof_X = dof_X.withColumnRenamed(j, f\"day_{i}\")\n",
    "        dof_X_active = dof_X.withColumnRenamed(j, f\"day_{i}\")\n",
    "    return dof_X,dof_X_active\n",
    "\n",
    "\n",
    "def get_days_active(X):\n",
    "    days_X_active = X.groupBy(\"sku\").agg({\"is_active\":\"sum\"})\n",
    "    total_days = X.groupBy(\"sku\").agg({\"sku\":\"count\"})\n",
    "    days_X_active = days_X_active.join(total_days, \"sku\")\n",
    "    days_X_active = days_X_active.withColumn(\"proportion_active\", F.col(\"sum(is_active)\")/F.col(\"count(sku)\"))\n",
    "    return days_X_active.select(\"sku\", \"proportion_active\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T21:49:48.57991Z",
     "iopub.status.busy": "2021-08-20T21:49:48.579547Z",
     "iopub.status.idle": "2021-08-20T21:49:48.606659Z",
     "shell.execute_reply": "2021-08-20T21:49:48.605655Z",
     "shell.execute_reply.started": "2021-08-20T21:49:48.579879Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .appName('meli-app') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T21:49:54.496353Z",
     "iopub.status.busy": "2021-08-20T21:49:54.495957Z",
     "iopub.status.idle": "2021-08-20T21:50:00.357759Z",
     "shell.execute_reply": "2021-08-20T21:50:00.356122Z",
     "shell.execute_reply.started": "2021-08-20T21:49:54.49632Z"
    },
    "id": "soqjPDefl2ph"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_path = \"./DATA\"\n",
    "\n",
    "train = spark.read.parquet(f\"{data_path}/train_data.parquet\")\n",
    "meta = spark.read.json(f\"{data_path}/items_static_metadata_full.jl\")\n",
    "test = spark.read.csv(f\"{data_path}/test_data.csv\", header = True)\n",
    "train0 = train # keep track of original data\n",
    "\n",
    "meta = meta.withColumn(\"item_domain_id\", F.regexp_replace(F.col(\"item_domain_id\"), \"^.*-\", \"\"))\n",
    "meta.filter(F.col(\"sku\") == 454273).show() # some with nulls\n",
    "meta = meta.na.fill(\"\")\n",
    "\n",
    "# Add metadata, items sold/domain id a\n",
    "test = test.withColumn(\"monid\", F.monotonically_increasing_id())\n",
    "test = test.join(meta[[\"sku\", \"item_domain_id\", \"site_id\"]], \"sku\", how = \"left\")\n",
    "test = test.orderBy(\"monid\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T21:50:00.36052Z",
     "iopub.status.busy": "2021-08-20T21:50:00.360087Z",
     "iopub.status.idle": "2021-08-20T21:50:12.325372Z",
     "shell.execute_reply": "2021-08-20T21:50:12.324039Z",
     "shell.execute_reply.started": "2021-08-20T21:50:00.360472Z"
    },
    "id": "P8esyO95l2pi"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "meta.filter(F.col(\"sku\") == 35253).show() # some with nulls"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T21:50:27.733236Z",
     "iopub.status.busy": "2021-08-20T21:50:27.732858Z",
     "iopub.status.idle": "2021-08-20T21:50:29.41133Z",
     "shell.execute_reply": "2021-08-20T21:50:29.408552Z",
     "shell.execute_reply.started": "2021-08-20T21:50:27.733203Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train.filter(F.col(\"sku\") == 35253).show() # some with nulls"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T21:50:53.9942Z",
     "iopub.status.busy": "2021-08-20T21:50:53.993741Z",
     "iopub.status.idle": "2021-08-20T21:50:58.416408Z",
     "shell.execute_reply": "2021-08-20T21:50:58.415055Z",
     "shell.execute_reply.started": "2021-08-20T21:50:53.994165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "counts_total = train.groupBy(\"sku\").count()\n",
    "counts_total = counts_total.groupBy(F.col(\"count\").alias(\"number_of_items\")).count().sort(F.asc(\"number_of_items\")).toPandas()\n",
    "counts_total[\"proportion\"] = 100 * counts_total[\"count\"] / counts_total[\"count\"].sum()\n",
    "expr = counts_total[counts_total[\"count\"] > 30].proportion.sum()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T15:53:27.258423Z",
     "iopub.status.busy": "2021-08-09T15:53:27.257979Z",
     "iopub.status.idle": "2021-08-09T15:53:41.33819Z",
     "shell.execute_reply": "2021-08-09T15:53:41.337086Z",
     "shell.execute_reply.started": "2021-08-09T15:53:27.258379Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.scatterplot(\"number_of_items\", \"proportion\", data = counts_total)\n",
    "print(f\"Counts > 30: {expr}\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T15:53:41.340327Z",
     "iopub.status.busy": "2021-08-09T15:53:41.339688Z",
     "iopub.status.idle": "2021-08-09T15:53:41.650603Z",
     "shell.execute_reply": "2021-08-09T15:53:41.649836Z",
     "shell.execute_reply.started": "2021-08-09T15:53:41.340281Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# rows with leading 0s of minutes actives\n",
    "tt = train.groupBy(\"sku\").agg(F.collect_list(\"minutes_active\").alias(\"vec\"))\n",
    "tt = tt.withColumn(\"to_remove\", count_zeros(F.col(\"vec\"))).drop(\"vec\")\n",
    "tt = tt.toPandas()\n",
    "plt.hist(tt.to_remove.astype(\"float\")[tt.to_remove > 0], bins = range(0, 60, 1))\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-09T15:53:41.652092Z",
     "iopub.status.busy": "2021-08-09T15:53:41.651622Z",
     "iopub.status.idle": "2021-08-09T15:54:13.08078Z",
     "shell.execute_reply": "2021-08-09T15:54:13.077169Z",
     "shell.execute_reply.started": "2021-08-09T15:53:41.652059Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# How many items have x ts values with minutes active > 0?\n",
    "counts = train.filter(F.col(\"minutes_active\") > 0).groupBy(\"sku\").agg({\"sku\":\"count\"}).withColumnRenamed(\"count(sku)\", \"counts\")\n",
    "counts = counts.groupBy(\"counts\").count()\n",
    "counts = counts.toPandas()\n",
    "counts[[\"proportion\"]] = 100 * counts.counts / counts.counts.sum()\n",
    "counts = counts.sort_values(\"counts\")\n",
    "expr = counts[counts[\"counts\"] > 30].proportion.sum()\n",
    "sns.scatterplot(\"counts\", \"proportion\", data = counts)\n",
    "print(f\"Counts > 30: {expr}\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-09T15:54:13.082043Z",
     "iopub.status.idle": "2021-08-09T15:54:13.082521Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Check if dates are consecutive for each SKU\n",
    "not_consecutives = train.groupBy(\"sku\").agg(are_consecutive_dates(F.collect_list(F.col(\"date\"))).alias(\"consecutive\"))\n",
    "not_consecutives.filter(F.col(\"consecutive\") == False).show()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-09T15:54:13.083782Z",
     "iopub.status.idle": "2021-08-09T15:54:13.08441Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# check if ts start at different dates\n",
    "mindate = train.groupBy(\"sku\").agg(F.min(\"date\"))\n",
    "mindate.select(\"min(date)\").distinct().show()\n",
    "\n",
    "# check if ts start at different dates\n",
    "maxdate = train.groupBy(\"sku\").agg(F.max(\"date\"))\n",
    "maxdate.select(\"max(date)\").distinct().show()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-08-09T15:54:13.085264Z",
     "iopub.status.idle": "2021-08-09T15:54:13.085783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train = train.withColumn('selling_rate', F.when(F.col(\"minutes_active\") > 0, F.col(\"sold_quantity\")/F.col(\"minutes_active\")).otherwise(F.lit(0)))\n",
    "train = train.withColumn('is_active', F.when(F.col(\"minutes_active\") > 0, F.lit(1)).otherwise(F.lit(0)))\n",
    "train_active = train.filter(F.col('is_active') == 1)\n",
    "\n",
    "window = create_window('sku', 'date')\n",
    "train = train.withColumn('id',  F.row_number().over(window))\n",
    "train = train.withColumn(\"is_train\", F.when(F.col(\"id\") <= 30, F.lit(1)).otherwise(F.lit(0)))\n",
    "train = train.withColumn(\"sku_split\", F.concat(F.col(\"sku\"), F.lit(\"_\"), F.col(\"is_train\").cast(T.StringType()))).drop(\"id\")\n",
    "\n",
    "train_active = train_active.withColumn('id',  F.row_number().over(window))\n",
    "train_active = train_active.withColumn(\"is_train\", F.when(F.col(\"id\") <= 30, F.lit(1)).otherwise(F.lit(0)))\n",
    "train_active = train_active.withColumn(\"sku_split\", F.concat(F.col(\"sku\"), F.lit(\"_\"), F.col(\"is_train\").cast(T.StringType()))).drop(\"id\")\n",
    "# Compute cumsum for items sold quantities\n",
    "\n",
    "\n",
    "window2 = create_window('sku_split', 'date')\n",
    "windowval = create_window(\"sku_split\", 'date', [Window.unboundedPreceding, 0])\n",
    "\n",
    "train = train.withColumn('cumsum', F.sum('sold_quantity').over(windowval))\n",
    "train_active = train_active.withColumn('cumsum', F.sum('sold_quantity').over(windowval))\n",
    "\n",
    "train = train.withColumn(\"max\", F.max(\"cumsum\").over(windowval) + 1)\n",
    "train_active = train_active.withColumn(\"max\", F.max(\"cumsum\").over(windowval) + 1)\n",
    "train = train.withColumn('cumsum_pc', F.col(\"cumsum\") / F.col(\"max\"))\n",
    "train_active = train_active.withColumn('cumsum_pc', F.col(\"cumsum\") / F.col(\"max\"))\n",
    "\n",
    "train = train.withColumn('id',  F.row_number().over(window2))\n",
    "train_active = train_active.withColumn('id',  F.row_number().over(window2))"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T17:55:25.647799Z",
     "iopub.status.busy": "2021-08-20T17:55:25.647121Z",
     "iopub.status.idle": "2021-08-20T17:55:26.135776Z",
     "shell.execute_reply": "2021-08-20T17:55:26.134624Z",
     "shell.execute_reply.started": "2021-08-20T17:55:25.64774Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validation = train.filter(F.col(\"is_train\") == 0)\n",
    "train = train.filter(F.col(\"is_train\") == 1)\n",
    "validation_active = train_active.filter(F.col(\"is_train\") == 0)\n",
    "train_active = train_active.filter(F.col(\"is_train\") == 1)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T17:55:30.250794Z",
     "iopub.status.busy": "2021-08-20T17:55:30.250297Z",
     "iopub.status.idle": "2021-08-20T17:55:30.304261Z",
     "shell.execute_reply": "2021-08-20T17:55:30.302915Z",
     "shell.execute_reply.started": "2021-08-20T17:55:30.250749Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "days_activity_train = get_days_active(train)\n",
    "days_activity_validation = get_days_active(validation)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T18:40:16.79372Z",
     "iopub.status.busy": "2021-08-20T18:40:16.793309Z",
     "iopub.status.idle": "2021-08-20T18:40:16.826972Z",
     "shell.execute_reply": "2021-08-20T18:40:16.826046Z",
     "shell.execute_reply.started": "2021-08-20T18:40:16.793683Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dof_train,dof_train_active = get_dof(train,train_active)\n",
    "dof_validation,dof_validation_active = get_dof(validation,validation_active)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-20T17:55:31.748886Z",
     "iopub.status.busy": "2021-08-20T17:55:31.74846Z",
     "iopub.status.idle": "2021-08-20T17:55:31.784519Z",
     "shell.execute_reply": "2021-08-20T17:55:31.783184Z",
     "shell.execute_reply.started": "2021-08-20T17:55:31.748853Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "rolling_windows = [1, 2, 3, 4, 5]\n",
    "\n",
    "for cumtype in [\"cumsum\", \"cumsum_pc\"]:\n",
    "    for interval in rolling_windows:\n",
    "        train = train.withColumn(f\"rolling_{cumtype}_{interval}\", F.avg(cumtype).over(create_window('sku', 'id', [-interval, 0])))\n",
    "        train_active = train_active.withColumn(f\"rolling_{cumtype}_{interval}\", F.avg(cumtype).over(create_window('sku', 'id', [-interval,0])))\n",
    "        validation = validation.withColumn(f\"rolling_{cumtype}_{interval}\", F.avg(cumtype).over(create_window('sku', 'id', [-interval, 0])))\n",
    "        validation_active = validation_active.withColumn(f\"rolling_{cumtype}_{interval}\", F.avg(cumtype).over(create_window('sku', 'id', [-interval, 0])))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "skus = train.select(\"sku\").distinct().rdd.flatMap(lambda x: x).collect()\n",
    "skus = np.random.choice(skus, 200).tolist()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.847587Z",
     "iopub.status.idle": "2021-07-27T17:11:17.84797Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q0 = train.filter(train.sku.isin(skus)).toPandas()\n",
    "q1 = validation.filter(train.sku.isin(skus)).toPandas()\n",
    "\n",
    "frames = q0.sku.unique()\n",
    "plot_frames_train_val(train = q0, validation = q1, frames = frames, main = \"Train vs validation\")\n",
    "plot_frames_train_val(train = q0[q0.minutes_active > 0], validation = q1[q1.minutes_active > 0], frames = frames, main = \"Train vs validation for both minutes active > 0\")\n",
    "plot_frames_train_val(train = q0, validation = q0[q0.minutes_active > 0], frames = frames, ax1_lab = \"train\", ax2_lab= \"Train minutes active > 0\", \n",
    "                      main = \"Train vs train minutes active > 0\") \n",
    "plot_frames_train_val(train = q1, validation = q1[q1.minutes_active > 0], frames = frames, ax1_lab = \"validation\", ax2_lab= \"Validation minutes active > 0\",\n",
    "                      main = \"Validation vs validation minutes active > 0\") "
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.848926Z",
     "iopub.status.idle": "2021-07-27T17:11:17.849375Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "q0 = train_active.filter(train_active.sku.isin(skus)).toPandas()\n",
    "q1 = validation_active.filter(train_active.sku.isin(skus)).toPandas()\n",
    "\n",
    "plot_frames_train_val(train = q0, validation = q1, frames = frames, main = \"Train active vs validation\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-08T08:14:31.917923Z",
     "iopub.status.busy": "2021-08-08T08:14:31.91742Z",
     "iopub.status.idle": "2021-08-08T08:14:31.994457Z",
     "shell.execute_reply": "2021-08-08T08:14:31.993271Z",
     "shell.execute_reply.started": "2021-08-08T08:14:31.917829Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "features_train = create_proportion_columns(train)\n",
    "features_train_active = create_proportion_columns(train_active)\n",
    "features_validation = create_proportion_columns(validation)\n",
    "features_validation_active = create_proportion_columns(validation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Generate time series for 30 days\n",
    "id = spark.range(1,31)\n",
    "sku = train.select(F.col(\"sku\")).distinct()\n",
    "dates_sku = id.crossJoin(sku)\n",
    "\n",
    "train = dates_sku.join(train, [\"sku\", \"id\"], how=\"left\")\n",
    "train_active = dates_sku.join(train_active, [\"sku\", \"id\"], how=\"left\")\n",
    "\n",
    "validation = dates_sku.join(validation, [\"sku\", \"id\"], how=\"left\")\n",
    "validation_active = dates_sku.join(validation_active, [\"sku\", \"id\"], how=\"left\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-30T01:13:38.311501Z",
     "iopub.status.busy": "2021-07-30T01:13:38.31114Z",
     "iopub.status.idle": "2021-07-30T01:13:38.491364Z",
     "shell.execute_reply": "2021-07-30T01:13:38.490363Z",
     "shell.execute_reply.started": "2021-07-30T01:13:38.311471Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Add metadata\n",
    "train = train.join(meta[[\"sku\", \"item_domain_id\", \"site_id\"]], \"sku\")\n",
    "train_active = train_active.join(meta[[\"sku\", \"item_domain_id\", \"site_id\"]], \"sku\")\n",
    "validation = validation.join(meta[[\"sku\", \"item_domain_id\", \"site_id\"]], \"sku\")\n",
    "validation_active = validation_active.join(meta[[\"sku\", \"item_domain_id\", \"site_id\"]], \"sku\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "to_drop = [\"date\", \"is_train\", \"sku_split\"]\n",
    "train = train.drop(*to_drop)\n",
    "validation = validation.drop(*to_drop)\n",
    "train_active = train_active.drop(*to_drop)\n",
    "validation_active = validation_active.drop(*to_drop)"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.852978Z",
     "iopub.status.idle": "2021-07-27T17:11:17.972078Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "windowval = create_window('sku', 'id', [Window.unboundedPreceding, 0])\n",
    "\n",
    "for item in [\"item_domain_id\", \"site_id\", \"currency\", \"max\"]:\n",
    "    train = forward_fill(windowval, train, item) # fill with last non null value\n",
    "    train_active = forward_fill(windowval, train_active, item) # fill with last non null value\n",
    "    validation = forward_fill(windowval, validation, item) # fill with last non null value\n",
    "    validation_active = forward_fill(windowval, validation_active, item) # fill with last non null value\n",
    "\n",
    "\n",
    "to_fill =  [\"sold_quantity\", \"minutes_active\", \"is_active\", \n",
    "            \"current_price\", \"cumsum\", \"selling_rate\"] + [f\"rolling_cumsum_{interval}\" for interval in rolling_windows] + [f\"rolling_cumsum_pc_{interval}\" for interval in rolling_windows] \n",
    "\n",
    "\n",
    "to_fill = dict(zip(to_fill, [-1 for i in range(len(to_fill))]))\n",
    "train = train.na.fill(to_fill)\n",
    "train_active = train_active.na.fill(to_fill).drop(\"is_active\")\n",
    "validation = validation.na.fill(to_fill)\n",
    "validation_active = validation_active.na.fill(to_fill).drop(\"is_active\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.976272Z",
     "iopub.status.idle": "2021-07-27T17:11:17.97668Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_active_min = train_active.select(\"sku\", \"id\", \"rolling_cumsum_1\", 'item_domain_id', \"site_id\")\n",
    "validation_active_min = validation_active.select(\"sku\", \"id\", \"rolling_cumsum_1\", 'item_domain_id', \"site_id\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train.printSchema()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.977572Z",
     "iopub.status.idle": "2021-07-27T17:11:17.97798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "validation.printSchema()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.979261Z",
     "iopub.status.idle": "2021-07-27T17:11:17.979671Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test.printSchema()"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.981932Z",
     "iopub.status.idle": "2021-07-27T17:11:17.982381Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "write_data(train,\"train.parquet\")\n",
    "write_data(validation,\"validation.parquet\")\n",
    "write_data(train_active,\"train_active.parquet\")\n",
    "write_data(validation_active,\"validation_active.parquet\")\n",
    "write_data(test,\"test.parquet\")\n",
    "\n",
    "write_data(train_active_min, \"train_active_min.parquet\")\n",
    "write_data(validation_active_min, \"validation_active_min.parquet\")\n",
    "\n",
    "write_data(features_train,\"features_train.parquet\")\n",
    "write_data(features_train_active,\"features_train_active.parquet\")\n",
    "write_data(features_validation,\"features_validation.parquet\")\n",
    "write_data(features_validation_active,\"features_validation_active.parquet\")\n",
    "\n",
    "write_data(dof_train,\"dof_train.parquet\")\n",
    "write_data(dof_train_active,\"dof_train_active.parquet\")\n",
    "write_data(dof_validation,\"dof_validation.parquet\")\n",
    "write_data(dof_validation_active,\"dof_validation_active.parquet\")\n",
    "\n",
    "write_data(days_activity_train, \"days_activity_train.parquet\")\n",
    "write_data(days_activity_validation, \"days_activity_validation.parquet\")"
   ],
   "outputs": [],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-07-27T17:11:17.983229Z",
     "iopub.status.idle": "2021-07-27T17:11:17.983654Z"
    },
    "id": "U-feHeEXqWUr"
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}